gatewayRef:
  name: ai-gateway

rateLimitPolicy:
  enabled: true
  labels: {}
  annotations: {}

  # ADD: define descriptors used by Limitador
  # This enables per-user AND per-model rate limiting
  descriptors:
    - key: user
      source: header
      headerName: x-user-id   # identifies the user
    - key: model
      source: header
      headerName: x-model     # identifies the model

  defaults:
    limits:
      default:
        rates:
          - limit: 100
            window: 1m

backends:
  fw-01:
    resourceName: fw-backend-01-svc
    schema: OpenAI
    prefix: /inference/v1
    fqdn:
      hostname: api.fireworks.ai
      port: 443
    apiKeySecretRef:
      name: fw-primary-apikey
      key: apiKey
    tlsHostname: api.fireworks.ai
  fw-02:
    resourceName: fw-backend-02-svc
    schema: OpenAI
    prefix: /inference/v1
    fqdn:
      hostname: api.fireworks.ai
      port: 443
    apiKeySecretRef:
      name: fw-primary-apikey
      key: apiKey
    tlsHostname: api.fireworks.ai
  gpt-01:
    resourceName: gpt-backend-01-svc
    schema: OpenAI
    fqdn:
      hostname: api.ai.kivoyo.com
      port: 443
    apiKeySecretRef:
      name: gpt-primary-apikey
      key: apiKey
    tlsHostname: api.ai.kivoyo.com
  gpt-02:
    resourceName: gpt-backend-02-svc
    schema: OpenAI
    fqdn:
      hostname: api.ai.kivoyo.com
      port: 443
    apiKeySecretRef:
      name: gpt-primary-apikey
      key: apiKey
    tlsHostname: api.ai.kivoyo.com
 

models:
  fireworks:
    enabled: true

    rateLimit:
      scope:
        - user
        - model

      limits:
        default:
          rates:
            - limit: 3
              window: 1m

    backends:
      aws-01:
        enabled: true
        ref: fw-01
        modelNameOverride: "accounts/fireworks/models/qwen3-vl-235b-a22b-instruct"
      aws-02:
        enabled: true
        ref: fw-02
        modelNameOverride: "accounts/fireworks/models/qwen3-vl-30b-a3b-thinking"

  gpt:
    enabled: true

    rateLimit:
      scope:
        - user
        - model

      limits:
        default:
          rates:
            - limit: 3
              window: 1m

    backends:
      aws-01:
        enabled: true
        ref: gpt-01
        modelNameOverride: "gpt-5"
      aws-02:
        enabled: true
        ref: gpt-02
        modelNameOverride: "gpt-5-mini"
