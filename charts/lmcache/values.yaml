# Default values for lmcache.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

global:
  nameOverride: ""
  fullnameOverride: ""

controllers:
  main:
    # -- Controller deployment strategy.
    strategy: RollingUpdate

    # -- Annotations for the controller pods.
    annotations: {}

    containers:
      main:
        # -- Container image repository.
        image:
          repository: "lmcache/vllm-openai"
          # -- Container image tag.
          tag: "0.1.0" # Use semantic versioning for image tags (e.0.0)
          # -- Container image pull policy.
          pullPolicy: IfNotPresent

        # -- Environment variables for the container.
        env:
          LMCACHE_USE_EXPERIMENTAL: "True"
          LMCACHE_CONFIG_FILE: "/etc/lmcache/lmcache_config.yaml"
          LMCACHE_LOG_LEVEL: "info"

        # -- Probes for the container.
        probes:
          liveness:
            enabled: true
            spec:
              httpGet:
                path: "/health"
                port: 8000
              initialDelaySeconds: 30
              periodSeconds: 10
              timeoutSeconds: 5
              failureThreshold: 3
          readiness:
            enabled: true
            spec:
              httpGet:
                path: "/health"
                port: 8000
              initialDelaySeconds: 5
              periodSeconds: 5
              timeoutSeconds: 3
              failureThreshold: 3

        # -- Resource requests and limits for the container.
        # We recommend adjusting these values based on your workload.
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
            nvidia.com/gpu: "1"
          limits:
            memory: "8Gi"
            cpu: "4000m"
            nvidia.com/gpu: "1"

podOptions:
  securityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    fsGroupChangePolicy: "OnRootMismatch"

# -- LMCache configuration.
lmcache:
  enabled: true
  chunk_size: 256
  local:
    cpu:
      size: 1024
    disk:
      path: "/tmp/lmcache"
      size: 1024
  remote_url: "redis://{{ .Values.redis.host }}:{{ .Values.redis.port }}"

# -- Service configuration.
service:
  main:
    controller: main
    type: ClusterIP
    ports:
      http:
        port: 80
        targetPort: 8000

# -- Ingress configuration.
ingress:
  main:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

# -- Persistence configuration.
persistence:
  lmcache-config:
    type: configMap
    name: lmcache-config
    advancedMounts:
      main:
        main:
          - path: /etc/lmcache

configMaps:
  lmcache-config:
    enabled: true
    data:
      lmcache_config.yaml: |
        enabled: {{ .Values.lmcache.enabled }}
        chunk_size: {{ .Values.lmcache.chunk_size }}
        local:
          cpu:
            size: {{ .Values.lmcache.local.cpu.size }}
          disk:
            path: "{{ .Values.lmcache.local.disk.path }}"
            size: {{ .Values.lmcache.local.disk.size }}
        remote_url: "{{ .Values.lmcache.remote_url }}"

# -- Node selector configuration.
nodeSelector: {}

# -- Tolerations configuration.
tolerations: []

# -- Affinity configuration.
affinity: {}

# -- RBAC configuration.
rbac:
  roles: {}

# -- Redis configuration.
redis:
  host: "redis-master.redis.svc.cluster.local"
  port: 6379